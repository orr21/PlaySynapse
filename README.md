# PlaySynapse: Sistema de AnalÃ­tica Deportiva

**Video Demo:** [https://youtu.be/yp8N_ug8NPM](https://youtu.be/yp8N_ug8NPM)

> **Trabajo Fin de MÃ¡ster - MÃ¡ster en Big Data & Data Engineering**  
> **Autor:** Ã“scar Rico RodrÃ­guez  
> **Tutores:** Jorge Centeno y Alberto GonzÃ¡lez  
> **Fecha:** Febrero 2026

## ğŸ“„ Resumen

**PlaySynapse** es una plataforma de ingenierÃ­a de datos diseÃ±ada para unificar la analÃ­tica deportiva histÃ³rica con la inmediatez de la inteligencia artificial. El proyecto responde a la necesidad de integrar fuentes heterogÃ©neas â€”desde registros estadÃ­sticos histÃ³ricos hasta flujos de datos de visiÃ³n por computadorâ€” en una arquitectura comÃºn que democratice el acceso a insights avanzados.

La soluciÃ³n implementada se basa en una arquitectura **Lakehouse contenerizada**. Para la gestiÃ³n de datos histÃ³ricos, se han desarrollado pipelines Batch orquestados con **Mage.ai** y procesados con **Polars**. Para el componente de tiempo real, se ha desplegado un sistema de Streaming basado en **Redpanda** que ingesta y procesa eventos de juego simulados, emulando la salida de modelos de visiÃ³n artificial. Finalmente, se ha integrado un mÃ³dulo de **IA Generativa** (Llama 3 vÃ­a Groq) que transforma estos datos estructurados en narrativas tÃ¡cticas ("AndrÃ©s Montes") visualizadas en tiempo real.

## ğŸ¯ Objetivos del Proyecto

1.  **Pipeline de Datos Unificado**: DiseÃ±ar un flujo capaz de procesar tanto informaciÃ³n histÃ³rica como eventos en tiempo real generados por modelos de visiÃ³n artificial.
2.  **Arquitectura HÃ­brida**: Implementar un sistema Batch + Streaming eficiente con almacenamiento Lakehouse (Medallion Architecture).
3.  **Insights con GenAI**: Aplicar tÃ©cnicas de inteligencia artificial para generar narrativas analÃ­ticas y comentarios en lenguaje natural a partir de mÃ©tricas deportivas.
4.  **Escalabilidad Multideporte**: DiseÃ±ar la plataforma con una visiÃ³n agnÃ³stica al deporte, permitiendo su adaptaciÃ³n a otros dominios de video-analÃ­tica.

## ğŸš€ CaracterÃ­sticas Principales

- **SimulaciÃ³n en Tiempo Real**: Capacidad de reproducir partidos histÃ³ricos sincronizados evento a evento.
- **Streaming de Baja Latencia**: Arquitectura basada en eventos utilizando Redpanda (Kafka compatible).
- **Data Lakehouse**: Almacenamiento escalable en MinIO (S3 compatible) con formato Delta Lake.
- **NarraciÃ³n AutomÃ¡tica**: Comentarista IA en vivo utilizando Groq (Llama 3).
- **OrquestaciÃ³n Moderna**: Pipelines de datos gestionados con Mage.ai.
- **VisualizaciÃ³n Interactiva**: Dashboard analÃ­tico (Streamlit) y App de narraciÃ³n en vivo (Gradio).

## ğŸ› ï¸ Arquitectura del Sistema

El flujo de datos sigue una arquitectura moderna de streaming y batch:

```mermaid
graph TD
    A[Simulator / NBA API] -->|Raw Events| B(Redpanda: nba_live)
    B -->|Consumer| C{Mage: Streaming Pipeline}
    C -->|Processed Events + AI Prompt| D(Redpanda: nba_gold_events)
    D -->|Consumer| E[NBA Live App (Gradio)]
    E -->|Narrative Generation| F[Groq LLM]

    G[Populate Historical Data] -->|Batch Pipeline| H{Mage: Batch ETL}
    H -->|Write Delta Tables| I[(MinIO: Bronze/Silver/Gold)]
    I -->|Query| J[NBA Dashboard (Streamlit)]
```

## ğŸ—ï¸ Estructura del Proyecto

- **`data_platform/`**: Orquestador **Mage**. Contiene los pipelines de datos (ingesta, transformaciÃ³n, streaming).
- **`nba_dashboard/`**: AplicaciÃ³n **Streamlit** para visualizaciÃ³n analÃ­tica histÃ³rica.
- **`nba_live_app/`**: AplicaciÃ³n **Gradio** para la narraciÃ³n en vivo con IA.
- **`realtime_simulator.py`**: Script de simulaciÃ³n que inyecta datos de partidos al sistema en tiempo real.
- **`docker-compose.yml`**: DefiniciÃ³n de infraestructura (contenedores).

## ğŸ’» Requisitos Previos

- **Docker** y **Docker Compose**.
- **Python 3.9+** (opcional, para scripts locales).
- API Key de **Groq** (para la narraciÃ³n con IA).

## ğŸš€ Inicio RÃ¡pido

### 1. ConfiguraciÃ³n

Clona el repositorio y configura las variables de entorno:

```bash
cp .env.example .env
# Edita .env y aÃ±ade tu GROQ_API_KEY
```

### 2. Despliegue

```bash
docker-compose up -d
```

Servicios disponibles:

- **Mage (Orquestador):** `http://localhost:6789`
- **Redpanda Console:** `http://localhost:8080`
- **MinIO Console:** `http://localhost:9001`
- **NBA Live App:** `http://localhost:7860`
- **NBA Dashboard:** `http://localhost:8501`

### 3. EjecuciÃ³n

1.  En **Mage**, activa el pipeline `nba_pbp_realtime`.
2.  Ejecuta el simulador localmente:
    ```bash
    pip install -r requirements.txt
    python realtime_simulator.py
    ```
3.  Abre la **NBA Live App** para ver la narraciÃ³n y el **NBA Dashboard** para anÃ¡lisis.

## ğŸ“Š TecnologÃ­as Utilizadas

| Componente          | TecnologÃ­a            | PropÃ³sito                     |
| :------------------ | :-------------------- | :---------------------------- |
| **Lenguaje**        | Python ğŸ             | LÃ³gica principal              |
| **OrquestaciÃ³n**    | Mage.ai ğŸ§™            | Pipelines Batch & Streaming   |
| **Streaming**       | Redpanda ğŸ¼           | Broker de eventos (Kafka API) |
| **Storage**         | MinIO ğŸª£              | Data Lake (S3 API)            |
| **Formato**         | Delta Lake ğŸ”º         | Tablas ACID                   |
| **Frontend**        | Streamlit & Gradio ğŸ¨ | UI AnalÃ­tica y Live           |
| **GenAI**           | Groq (Llama 3) âš¡     | GeneraciÃ³n de texto           |
| **Infraestructura** | Docker ğŸ³             | Contenedores                  |
